{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTETdipRKslE"
      },
      "source": [
        "Copyright (c) 2021, salesforce.com, inc.  \n",
        "All rights reserved.  \n",
        "SPDX-License-Identifier: BSD-3-Clause  \n",
        "For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db18ta9YKslH"
      },
      "source": [
        "### Colab\n",
        "\n",
        "Try this notebook on [Colab](http://colab.research.google.com/github/salesforce/ai-economist/blob/master/tutorials/multi_agent_training_with_rllib.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u8q3nesKslH"
      },
      "source": [
        "### Prerequisites\n",
        "It is helpful to be familiar with **Foundation**, a multi-agent economic simulator built for the AI Economist ([paper here](https://arxiv.org/abs/2004.13332)). If you haven't worked with Foundation before, we highly recommend taking a look at our other tutorials:\n",
        "\n",
        "- [Foundation: the Basics](https://github.com/salesforce/ai-economist/blob/master/tutorials/economic_simulation_basic.ipynb)\n",
        "- [Extending Foundation](https://github.com/salesforce/ai-economist/blob/master/tutorials/economic_simulation_advanced.ipynb)\n",
        "- [Optimal Taxation Theory and Simulation](https://github.com/salesforce/ai-economist/blob/master/tutorials/optimal_taxation_theory_and_simulation.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGkKf0toKslI"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxskLNk1KslI"
      },
      "source": [
        "Welcome! This tutorial is the first of a series on doing distributed multi-agent reinforcement learning (MARL). Here, we specifically demonstrate how to integrate our multi-agent economic simulation, [Foundation](https://github.com/salesforce/ai-economist/tree/master/ai_economist/foundation), with [RLlib](https://github.com/ray-project/ray/tree/master/rllib), an open-source library for reinforcement learning. We chose to use RLlib, as it provides an easy-to-use and flexible library for MARL. A detailed documentation on RLlib is available [here](https://docs.ray.io/en/master/rllib.html).\n",
        "\n",
        "We put together these tutorial notebook with the following key goals in mind:\n",
        "- Provide an exposition to MARL. While there are many libraries and references out there for single-agent RL training, MARL training is not discussed as much, and there aren't many multi-agent rl libraries.\n",
        "- Provide reference starting code to perform MARL training so the AI Economist community can focus more on building meaningful extensions to Foundation and better-performant algorithms.\n",
        "\n",
        "We will cover the following concepts in this tutorial:\n",
        "1. Adding an *environment wrapper* to make the economic simulation compatible with RLlib.\n",
        "2. Creating a *trainer* object that holds the (multi-agent) policies for environment interaction.\n",
        "3. Training all the agents in the economic simulation.\n",
        "4. Generate a rollout using the trainer object and visualize it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4JZv1MbKslJ"
      },
      "source": [
        "### Dependencies:\n",
        "You can install the ai-economist package using \n",
        "- the pip package manager OR\n",
        "- by cloning the ai-economist package and installing the requirements (we shall use this when running on Colab):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YhRHQptlKslK",
        "outputId": "eefce6db-28ac-42d7-9b10-107c9c5d905b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ai-economist'...\n",
            "remote: Enumerating objects: 212, done.\u001b[K\n",
            "remote: Counting objects: 100% (212/212), done.\u001b[K\n",
            "remote: Compressing objects: 100% (160/160), done.\u001b[K\n",
            "remote: Total 212 (delta 65), reused 192 (delta 48), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (212/212), 1.97 MiB | 23.40 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "/content/ai-economist\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/ai-economist\n",
            "Requirement already satisfied: appdirs==1.4.4 in /usr/local/lib/python3.7/dist-packages (from ai-economist==1.7.1) (1.4.4)\n",
            "Collecting appnope==0.1.2\n",
            "  Downloading appnope-0.1.2-py2.py3-none-any.whl (4.3 kB)\n",
            "Collecting argon2-cffi==20.1.0\n",
            "  Downloading argon2_cffi-20.1.0-cp35-abi3-manylinux1_x86_64.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting astroid==2.5.6\n",
            "  Downloading astroid-2.5.6-py3-none-any.whl (219 kB)\n",
            "\u001b[K     |████████████████████████████████| 219 kB 33.3 MB/s \n",
            "\u001b[?25hCollecting async-generator==1.10\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Collecting attrs==21.2.0\n",
            "  Downloading attrs-21.2.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.7/dist-packages (from ai-economist==1.7.1) (0.2.0)\n",
            "Collecting beautifulsoup4==4.9.3\n",
            "  Downloading beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 79.9 MB/s \n",
            "\u001b[?25hCollecting black==21.5b1\n",
            "  Downloading black-21.5b1-py3-none-any.whl (137 kB)\n",
            "\u001b[K     |████████████████████████████████| 137 kB 82.5 MB/s \n",
            "\u001b[?25hCollecting bleach==3.3.0\n",
            "  Downloading bleach-3.3.0-py2.py3-none-any.whl (283 kB)\n",
            "\u001b[K     |████████████████████████████████| 283 kB 76.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: bs4==0.0.1 in /usr/local/lib/python3.7/dist-packages (from ai-economist==1.7.1) (0.0.1)\n",
            "Collecting certifi==2020.12.5\n",
            "  Downloading certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 80.0 MB/s \n",
            "\u001b[?25hCollecting cffi==1.14.5\n",
            "  Downloading cffi-1.14.5-cp37-cp37m-manylinux1_x86_64.whl (402 kB)\n",
            "\u001b[K     |████████████████████████████████| 402 kB 81.0 MB/s \n",
            "\u001b[?25hCollecting chardet==4.0.0\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[K     |████████████████████████████████| 178 kB 80.6 MB/s \n",
            "\u001b[?25hCollecting click==8.0.1\n",
            "  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting decorator==5.0.9\n",
            "  Downloading decorator-5.0.9-py3-none-any.whl (8.9 kB)\n",
            "Requirement already satisfied: defusedxml==0.7.1 in /usr/local/lib/python3.7/dist-packages (from ai-economist==1.7.1) (0.7.1)\n",
            "Collecting entrypoints==0.3\n",
            "  Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: et-xmlfile==1.1.0 in /usr/local/lib/python3.7/dist-packages (from ai-economist==1.7.1) (1.1.0)\n",
            "Collecting flake8==3.9.2\n",
            "  Downloading flake8-3.9.2-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting GPUtil==1.4.0\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from ai-economist==1.7.1) (2.10)\n",
            "Collecting iniconfig==1.1.1\n",
            "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
            "Collecting ipykernel==5.5.5\n",
            "  Downloading ipykernel-5.5.5-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 80.6 MB/s \n",
            "\u001b[?25hCollecting ipython==7.31.1\n",
            "  Downloading ipython-7.31.1-py3-none-any.whl (792 kB)\n",
            "\u001b[K     |████████████████████████████████| 792 kB 69.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.7/dist-packages (from ai-economist==1.7.1) (0.2.0)\n",
            "Collecting ipywidgets==7.6.3\n",
            "  Downloading ipywidgets-7.6.3-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[K     |████████████████████████████████| 121 kB 90.7 MB/s \n",
            "\u001b[?25hCollecting isort==5.8.0\n",
            "  Downloading isort-5.8.0-py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 84.7 MB/s \n",
            "\u001b[?25hCollecting jedi==0.18.0\n",
            "  Downloading jedi-0.18.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 86.1 MB/s \n",
            "\u001b[?25hCollecting Jinja2==3.0.1\n",
            "  Downloading Jinja2-3.0.1-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 87.9 MB/s \n",
            "\u001b[?25hCollecting jsonschema==3.2.0\n",
            "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting jupyter==1.0.0\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Requirement already satisfied: jupyter-client==6.1.12 in /usr/local/lib/python3.7/dist-packages (from ai-economist==1.7.1) (6.1.12)\n",
            "Collecting jupyter-console==6.4.0\n",
            "  Downloading jupyter_console-6.4.0-py3-none-any.whl (22 kB)\n",
            "Collecting jupyter-core==4.7.1\n",
            "  Downloading jupyter_core-4.7.1-py3-none-any.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 770 kB/s \n",
            "\u001b[?25hCollecting jupyterlab-pygments==0.1.2\n",
            "  Downloading jupyterlab_pygments-0.1.2-py2.py3-none-any.whl (4.6 kB)\n",
            "Collecting jupyterlab-widgets==1.0.0\n",
            "  Downloading jupyterlab_widgets-1.0.0-py3-none-any.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 72.3 MB/s \n",
            "\u001b[?25hCollecting kiwisolver==1.3.1\n",
            "  Downloading kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 74.3 MB/s \n",
            "\u001b[?25hCollecting lazy-object-proxy==1.6.0\n",
            "  Downloading lazy_object_proxy-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting lz4==3.1.3\n",
            "  Downloading lz4-3.1.3-cp37-cp37m-manylinux2010_x86_64.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 74.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe==2.0.1 in /usr/local/lib/python3.7/dist-packages (from ai-economist==1.7.1) (2.0.1)\n",
            "Collecting matplotlib==3.2.1\n",
            "  Downloading matplotlib-3.2.1-cp37-cp37m-manylinux1_x86_64.whl (12.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4 MB 76.4 MB/s \n",
            "\u001b[?25hCollecting matplotlib-inline==0.1.2\n",
            "  Downloading matplotlib_inline-0.1.2-py3-none-any.whl (8.2 kB)\n",
            "Collecting mccabe==0.6.1\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: mistune==0.8.4 in /usr/local/lib/python3.7/dist-packages (from ai-economist==1.7.1) (0.8.4)\n",
            "Collecting mypy-extensions==0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Collecting nbclient==0.5.3\n",
            "  Downloading nbclient-0.5.3-py3-none-any.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting nbconvert==6.0.7\n",
            "  Downloading nbconvert-6.0.7-py3-none-any.whl (552 kB)\n",
            "\u001b[K     |████████████████████████████████| 552 kB 82.2 MB/s \n",
            "\u001b[?25hCollecting nbformat==5.1.3\n",
            "  Downloading nbformat-5.1.3-py3-none-any.whl (178 kB)\n",
            "\u001b[K     |████████████████████████████████| 178 kB 80.8 MB/s \n",
            "\u001b[?25hCollecting nest-asyncio==1.5.1\n",
            "  Downloading nest_asyncio-1.5.1-py3-none-any.whl (5.0 kB)\n",
            "Collecting notebook==6.4.1\n",
            "  Downloading notebook-6.4.1-py3-none-any.whl (9.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.7 MB 30.3 MB/s \n",
            "\u001b[?25hCollecting numpy==1.21.0\n",
            "  Downloading numpy-1.21.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 53.0 MB/s \n",
            "\u001b[?25hCollecting openpyxl==3.0.7\n",
            "  Downloading openpyxl-3.0.7-py2.py3-none-any.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 84.7 MB/s \n",
            "\u001b[?25hCollecting packaging==20.9\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 6.8 MB/s \n",
            "\u001b[?25hCollecting pandas==1.2.4\n",
            "  Downloading pandas-1.2.4-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 75.3 MB/s \n",
            "\u001b[?25hCollecting pandocfilters==1.4.3\n",
            "  Downloading pandocfilters-1.4.3.tar.gz (16 kB)\n",
            "Collecting parso==0.8.2\n",
            "  Downloading parso-0.8.2-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting pathspec==0.8.1\n",
            "  Downloading pathspec-0.8.1-py2.py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: pexpect==4.8.0 in /usr/local/lib/python3.7/dist-packages (from ai-economist==1.7.1) (4.8.0)\n",
            "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.7/dist-packages (from ai-economist==1.7.1) (0.7.5)\n",
            "Collecting Pillow==9.0.1\n",
            "  Downloading Pillow-9.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 75.5 MB/s \n",
            "\u001b[?25hCollecting pluggy==0.13.1\n",
            "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
            "Collecting prometheus-client==0.10.1\n",
            "  Downloading prometheus_client-0.10.1-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.7 MB/s \n",
            "\u001b[?25hCollecting prompt-toolkit==3.0.18\n",
            "  Downloading prompt_toolkit-3.0.18-py3-none-any.whl (367 kB)\n",
            "\u001b[K     |████████████████████████████████| 367 kB 82.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.7/dist-packages (from ai-economist==1.7.1) (0.7.0)\n",
            "Collecting py==1.10.0\n",
            "  Downloading py-1.10.0-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 8.5 MB/s \n",
            "\u001b[?25hCollecting pycodestyle==2.7.0\n",
            "  Downloading pycodestyle-2.7.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 703 kB/s \n",
            "\u001b[?25hCollecting pycparser==2.20\n",
            "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 79.4 MB/s \n",
            "\u001b[?25hCollecting pycryptodome==3.10.1\n",
            "  Downloading pycryptodome-3.10.1-cp35-abi3-manylinux2010_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 50.1 MB/s \n",
            "\u001b[?25hCollecting pyflakes==2.3.1\n",
            "  Downloading pyflakes-2.3.1-py2.py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 7.9 MB/s \n",
            "\u001b[?25hCollecting Pygments==2.9.0\n",
            "  Downloading Pygments-2.9.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 81.8 MB/s \n",
            "\u001b[?25hCollecting pylint==2.8.2\n",
            "  Downloading pylint-2.8.2-py3-none-any.whl (357 kB)\n",
            "\u001b[K     |████████████████████████████████| 357 kB 88.6 MB/s \n",
            "\u001b[?25hCollecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 7.0 MB/s \n",
            "\u001b[?25hCollecting pyrsistent==0.17.3\n",
            "  Downloading pyrsistent-0.17.3.tar.gz (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 80.9 MB/s \n",
            "\u001b[?25hCollecting pytest==6.2.4\n",
            "  Downloading pytest-6.2.4-py3-none-any.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 82.0 MB/s \n",
            "\u001b[?25hCollecting python-dateutil==2.8.1\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "\u001b[K     |████████████████████████████████| 227 kB 76.5 MB/s \n",
            "\u001b[?25hCollecting pytz==2021.1\n",
            "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
            "\u001b[K     |████████████████████████████████| 510 kB 83.9 MB/s \n",
            "\u001b[?25hCollecting pyyaml==5.4.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 82.5 MB/s \n",
            "\u001b[?25hCollecting pyzmq==22.0.3\n",
            "  Downloading pyzmq-22.0.3-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 75.9 MB/s \n",
            "\u001b[?25hCollecting qtconsole==5.1.0\n",
            "  Downloading qtconsole-5.1.0-py3-none-any.whl (119 kB)\n",
            "\u001b[K     |████████████████████████████████| 119 kB 66.1 MB/s \n",
            "\u001b[?25hCollecting QtPy==1.9.0\n",
            "  Downloading QtPy-1.9.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting regex==2021.4.4\n",
            "  Downloading regex-2021.4.4-cp37-cp37m-manylinux2014_x86_64.whl (720 kB)\n",
            "\u001b[K     |████████████████████████████████| 720 kB 87.9 MB/s \n",
            "\u001b[?25hCollecting requests==2.25.1\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 10.1 MB/s \n",
            "\u001b[?25hCollecting scipy==1.6.3\n",
            "  Downloading scipy-1.6.3-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 27.4 MB 789 kB/s \n",
            "\u001b[?25hCollecting Send2Trash==1.5.0\n",
            "  Downloading Send2Trash-1.5.0-py3-none-any.whl (12 kB)\n",
            "Collecting six==1.16.0\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting soupsieve==2.2.1\n",
            "  Downloading soupsieve-2.2.1-py3-none-any.whl (33 kB)\n",
            "Collecting terminado==0.10.0\n",
            "  Downloading terminado-0.10.0-py3-none-any.whl (14 kB)\n",
            "Collecting testpath==0.5.0\n",
            "  Downloading testpath-0.5.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.7/dist-packages (from ai-economist==1.7.1) (0.10.2)\n",
            "Collecting tornado==6.1\n",
            "  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\n",
            "\u001b[K     |████████████████████████████████| 428 kB 90.2 MB/s \n",
            "\u001b[?25hCollecting tqdm==4.60.0\n",
            "  Downloading tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting traitlets==5.0.5\n",
            "  Downloading traitlets-5.0.5-py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 12.3 MB/s \n",
            "\u001b[?25hCollecting typing-extensions==3.10.0.0\n",
            "  Downloading typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
            "Collecting urllib3==1.26.5\n",
            "  Downloading urllib3-1.26.5-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 68.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth==0.2.5 in /usr/local/lib/python3.7/dist-packages (from ai-economist==1.7.1) (0.2.5)\n",
            "Requirement already satisfied: webencodings==0.5.1 in /usr/local/lib/python3.7/dist-packages (from ai-economist==1.7.1) (0.5.1)\n",
            "Collecting widgetsnbextension==3.5.1\n",
            "  Downloading widgetsnbextension-3.5.1-py2.py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 53.9 MB/s \n",
            "\u001b[?25hCollecting wrapt==1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Collecting typed-ast<1.5,>=1.4.0\n",
            "  Downloading typed_ast-1.4.3-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
            "\u001b[K     |████████████████████████████████| 743 kB 71.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click==8.0.1->ai-economist==1.7.1) (4.13.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython==7.31.1->ai-economist==1.7.1) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click==8.0.1->ai-economist==1.7.1) (3.9.0)\n",
            "Building wheels for collected packages: GPUtil, pandocfilters, pyrsistent, wrapt\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=3a9b0b945855410aa81b5ce38f3ddc81d2836c2a8ae7db35c5e41a8a05fd80dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "  Building wheel for pandocfilters (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandocfilters: filename=pandocfilters-1.4.3-py3-none-any.whl size=8007 sha256=d6483e51f28c69bc2e21930a9614d1b4827b17e342ca14232c8dd671cc7c53a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/81/34/545dc2fbf0e9137811e901108d37fc04650e81d48f97078000\n",
            "  Building wheel for pyrsistent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyrsistent: filename=pyrsistent-0.17.3-cp37-cp37m-linux_x86_64.whl size=98077 sha256=423241526e1f9d93583a4b0cdfe9b8e014245c0c5c2ba965e92f3aaea4abb4c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/52/bf/71258a1d7b3c8cbe1ee53f9314c6f65f20385481eaee573cc5\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68723 sha256=5e06d49a98a0b08ce56975f0fd24befbdede96c06dc0039d5b5115ad493ac5d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built GPUtil pandocfilters pyrsistent wrapt\n",
            "Installing collected packages: typing-extensions, traitlets, six, pyrsistent, attrs, tornado, pyzmq, python-dateutil, pyparsing, parso, jupyter-core, jsonschema, Pygments, pycparser, prompt-toolkit, packaging, nest-asyncio, nbformat, matplotlib-inline, jedi, decorator, async-generator, testpath, pandocfilters, nbclient, jupyterlab-pygments, Jinja2, ipython, entrypoints, cffi, bleach, terminado, Send2Trash, prometheus-client, nbconvert, ipykernel, argon2-cffi, notebook, wrapt, widgetsnbextension, typed-ast, soupsieve, QtPy, lazy-object-proxy, jupyterlab-widgets, urllib3, regex, qtconsole, pytz, pyflakes, pycodestyle, py, pluggy, pathspec, numpy, mypy-extensions, mccabe, kiwisolver, jupyter-console, isort, ipywidgets, iniconfig, cycler, click, chardet, certifi, beautifulsoup4, astroid, tqdm, scipy, requests, pyyaml, pytest, pylint, pycryptodome, Pillow, pandas, openpyxl, matplotlib, lz4, jupyter, GPUtil, flake8, black, appnope, ai-economist\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: traitlets\n",
            "    Found existing installation: traitlets 5.1.1\n",
            "    Uninstalling traitlets-5.1.1:\n",
            "      Successfully uninstalled traitlets-5.1.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: pyrsistent\n",
            "    Found existing installation: pyrsistent 0.18.1\n",
            "    Uninstalling pyrsistent-0.18.1:\n",
            "      Successfully uninstalled pyrsistent-0.18.1\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 22.1.0\n",
            "    Uninstalling attrs-22.1.0:\n",
            "      Successfully uninstalled attrs-22.1.0\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "  Attempting uninstall: pyzmq\n",
            "    Found existing installation: pyzmq 23.2.1\n",
            "    Uninstalling pyzmq-23.2.1:\n",
            "      Successfully uninstalled pyzmq-23.2.1\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: parso\n",
            "    Found existing installation: parso 0.8.3\n",
            "    Uninstalling parso-0.8.3:\n",
            "      Successfully uninstalled parso-0.8.3\n",
            "  Attempting uninstall: jupyter-core\n",
            "    Found existing installation: jupyter-core 4.11.1\n",
            "    Uninstalling jupyter-core-4.11.1:\n",
            "      Successfully uninstalled jupyter-core-4.11.1\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.3.3\n",
            "    Uninstalling jsonschema-4.3.3:\n",
            "      Successfully uninstalled jsonschema-4.3.3\n",
            "  Attempting uninstall: Pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "  Attempting uninstall: pycparser\n",
            "    Found existing installation: pycparser 2.21\n",
            "    Uninstalling pycparser-2.21:\n",
            "      Successfully uninstalled pycparser-2.21\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 2.0.10\n",
            "    Uninstalling prompt-toolkit-2.0.10:\n",
            "      Successfully uninstalled prompt-toolkit-2.0.10\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.3\n",
            "    Uninstalling packaging-21.3:\n",
            "      Successfully uninstalled packaging-21.3\n",
            "  Attempting uninstall: nbformat\n",
            "    Found existing installation: nbformat 5.7.0\n",
            "    Uninstalling nbformat-5.7.0:\n",
            "      Successfully uninstalled nbformat-5.7.0\n",
            "  Attempting uninstall: decorator\n",
            "    Found existing installation: decorator 4.4.2\n",
            "    Uninstalling decorator-4.4.2:\n",
            "      Successfully uninstalled decorator-4.4.2\n",
            "  Attempting uninstall: testpath\n",
            "    Found existing installation: testpath 0.6.0\n",
            "    Uninstalling testpath-0.6.0:\n",
            "      Successfully uninstalled testpath-0.6.0\n",
            "  Attempting uninstall: pandocfilters\n",
            "    Found existing installation: pandocfilters 1.5.0\n",
            "    Uninstalling pandocfilters-1.5.0:\n",
            "      Successfully uninstalled pandocfilters-1.5.0\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 7.9.0\n",
            "    Uninstalling ipython-7.9.0:\n",
            "      Successfully uninstalled ipython-7.9.0\n",
            "  Attempting uninstall: entrypoints\n",
            "    Found existing installation: entrypoints 0.4\n",
            "    Uninstalling entrypoints-0.4:\n",
            "      Successfully uninstalled entrypoints-0.4\n",
            "  Attempting uninstall: cffi\n",
            "    Found existing installation: cffi 1.15.1\n",
            "    Uninstalling cffi-1.15.1:\n",
            "      Successfully uninstalled cffi-1.15.1\n",
            "  Attempting uninstall: bleach\n",
            "    Found existing installation: bleach 5.0.1\n",
            "    Uninstalling bleach-5.0.1:\n",
            "      Successfully uninstalled bleach-5.0.1\n",
            "  Attempting uninstall: terminado\n",
            "    Found existing installation: terminado 0.13.3\n",
            "    Uninstalling terminado-0.13.3:\n",
            "      Successfully uninstalled terminado-0.13.3\n",
            "  Attempting uninstall: Send2Trash\n",
            "    Found existing installation: Send2Trash 1.8.0\n",
            "    Uninstalling Send2Trash-1.8.0:\n",
            "      Successfully uninstalled Send2Trash-1.8.0\n",
            "  Attempting uninstall: nbconvert\n",
            "    Found existing installation: nbconvert 5.6.1\n",
            "    Uninstalling nbconvert-5.6.1:\n",
            "      Successfully uninstalled nbconvert-5.6.1\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 5.3.4\n",
            "    Uninstalling ipykernel-5.3.4:\n",
            "      Successfully uninstalled ipykernel-5.3.4\n",
            "  Attempting uninstall: notebook\n",
            "    Found existing installation: notebook 5.5.0\n",
            "    Uninstalling notebook-5.5.0:\n",
            "      Successfully uninstalled notebook-5.5.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.1\n",
            "    Uninstalling widgetsnbextension-3.6.1:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.1\n",
            "  Attempting uninstall: jupyterlab-widgets\n",
            "    Found existing installation: jupyterlab-widgets 3.0.3\n",
            "    Uninstalling jupyterlab-widgets-3.0.3:\n",
            "      Successfully uninstalled jupyterlab-widgets-3.0.3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2022.6.2\n",
            "    Uninstalling regex-2022.6.2:\n",
            "      Successfully uninstalled regex-2022.6.2\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2022.4\n",
            "    Uninstalling pytz-2022.4:\n",
            "      Successfully uninstalled pytz-2022.4\n",
            "  Attempting uninstall: py\n",
            "    Found existing installation: py 1.11.0\n",
            "    Uninstalling py-1.11.0:\n",
            "      Successfully uninstalled py-1.11.0\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.4.4\n",
            "    Uninstalling kiwisolver-1.4.4:\n",
            "      Successfully uninstalled kiwisolver-1.4.4\n",
            "  Attempting uninstall: jupyter-console\n",
            "    Found existing installation: jupyter-console 6.1.0\n",
            "    Uninstalling jupyter-console-6.1.0:\n",
            "      Successfully uninstalled jupyter-console-6.1.0\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 3.0.4\n",
            "    Uninstalling chardet-3.0.4:\n",
            "      Successfully uninstalled chardet-3.0.4\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2022.9.24\n",
            "    Uninstalling certifi-2022.9.24:\n",
            "      Successfully uninstalled certifi-2022.9.24\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.1\n",
            "    Uninstalling tqdm-4.64.1:\n",
            "      Successfully uninstalled tqdm-4.64.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: openpyxl\n",
            "    Found existing installation: openpyxl 3.0.10\n",
            "    Uninstalling openpyxl-3.0.10:\n",
            "      Successfully uninstalled openpyxl-3.0.10\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Running setup.py develop for ai-economist\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nltk 3.7 requires regex>=2021.8.3, but you have regex 2021.4.4 which is incompatible.\n",
            "moviepy 0.2.3.5 requires decorator<5.0,>=4.0.2, but you have decorator 5.0.9 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=5.3.4, but you have ipykernel 5.5.5 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=7.9.0, but you have ipython 7.31.1 which is incompatible.\n",
            "google-colab 1.0.0 requires notebook~=5.5.0, but you have notebook 6.4.1 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0, but you have tornado 6.1 which is incompatible.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.0.1 which is incompatible.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.0.1 which is incompatible.\u001b[0m\n",
            "Successfully installed GPUtil-1.4.0 Jinja2-3.0.1 Pillow-9.0.1 Pygments-2.9.0 QtPy-1.9.0 Send2Trash-1.5.0 ai-economist-1.7.1 appnope-0.1.2 argon2-cffi-20.1.0 astroid-2.5.6 async-generator-1.10 attrs-21.2.0 beautifulsoup4-4.9.3 black-21.5b1 bleach-3.3.0 certifi-2020.12.5 cffi-1.14.5 chardet-4.0.0 click-8.0.1 cycler-0.10.0 decorator-5.0.9 entrypoints-0.3 flake8-3.9.2 iniconfig-1.1.1 ipykernel-5.5.5 ipython-7.31.1 ipywidgets-7.6.3 isort-5.8.0 jedi-0.18.0 jsonschema-3.2.0 jupyter-1.0.0 jupyter-console-6.4.0 jupyter-core-4.7.1 jupyterlab-pygments-0.1.2 jupyterlab-widgets-1.0.0 kiwisolver-1.3.1 lazy-object-proxy-1.6.0 lz4-3.1.3 matplotlib-3.2.1 matplotlib-inline-0.1.2 mccabe-0.6.1 mypy-extensions-0.4.3 nbclient-0.5.3 nbconvert-6.0.7 nbformat-5.1.3 nest-asyncio-1.5.1 notebook-6.4.1 numpy-1.21.0 openpyxl-3.0.7 packaging-20.9 pandas-1.2.4 pandocfilters-1.4.3 parso-0.8.2 pathspec-0.8.1 pluggy-0.13.1 prometheus-client-0.10.1 prompt-toolkit-3.0.18 py-1.10.0 pycodestyle-2.7.0 pycparser-2.20 pycryptodome-3.10.1 pyflakes-2.3.1 pylint-2.8.2 pyparsing-2.4.7 pyrsistent-0.17.3 pytest-6.2.4 python-dateutil-2.8.1 pytz-2021.1 pyyaml-5.4.1 pyzmq-22.0.3 qtconsole-5.1.0 regex-2021.4.4 requests-2.25.1 scipy-1.6.3 six-1.16.0 soupsieve-2.2.1 terminado-0.10.0 testpath-0.5.0 tornado-6.1 tqdm-4.60.0 traitlets-5.0.5 typed-ast-1.4.3 typing-extensions-3.10.0.0 urllib3-1.26.5 widgetsnbextension-3.5.1 wrapt-1.12.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "PIL",
                  "certifi",
                  "cffi",
                  "cycler",
                  "dateutil",
                  "decorator",
                  "ipykernel",
                  "jupyter_core",
                  "kiwisolver",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "prompt_toolkit",
                  "pygments",
                  "pyparsing",
                  "six",
                  "tornado",
                  "traitlets",
                  "typing_extensions",
                  "zmq"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Restarting the Python runtime! Please (re-)run the cells below.\n"
          ]
        }
      ],
      "source": [
        "# import os, signal, sys, time\n",
        "# IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "# if IN_COLAB:\n",
        "#     !git clone https://github.com/matyascorvinus/ai-economist\n",
        "\n",
        "#     %cd ai-economist\n",
        "#     !pip install -e .\n",
        "    \n",
        "#     # Restart the Python runtime to automatically use the installed packages\n",
        "#     print(\"\\n\\nRestarting the Python runtime! Please (re-)run the cells below.\")\n",
        "#     time.sleep(1)\n",
        "#     #os.kill(os.getpid(), signal.SIGKILL)\n",
        "# else:\n",
        "#     ! pip install ai-economist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu9CtjfzKslL"
      },
      "source": [
        "Install OpenAI Gym to help define the environment's observation and action spaces for use with RLlib."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8L6nUQInKslM"
      },
      "source": [
        "Install the `RLlib` reinforcement learning library:\n",
        "- First, install TensorFlow\n",
        "- Then, install ray[rllib]\n",
        "\n",
        "Note: RLlib natively supports TensorFlow (including TensorFlow Eager) as well as PyTorch, but most of its internals are framework agnostic. Here's a relevant [blogpost](https://medium.com/distributed-computing-with-ray/lessons-from-implementing-12-deep-rl-algorithms-in-tf-and-pytorch-1b412009297d) that compares running RLlib algorithms with TF and PyTorch. Overall, TF seems to run a bit faster than PyTorch, in our experience, and we will use that in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjbKL75JKslN",
        "outputId": "c1882eb2-bca6-432e-8673-7d1eee954e23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ray[rllib] in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (2.0.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from ray[rllib]) (1.0.4)\n",
            "Requirement already satisfied: jsonschema in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from ray[rllib]) (4.16.0)\n",
            "Requirement already satisfied: requests in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from ray[rllib]) (2.28.1)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.15.3 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from ray[rllib]) (3.19.6)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from ray[rllib]) (1.23.4)\n",
            "Requirement already satisfied: pyyaml in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from ray[rllib]) (6.0)\n",
            "Requirement already satisfied: grpcio<=1.43.0,>=1.42.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from ray[rllib]) (1.43.0)\n",
            "Requirement already satisfied: filelock in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from ray[rllib]) (3.8.0)\n",
            "Requirement already satisfied: aiosignal in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from ray[rllib]) (1.2.0)\n",
            "Requirement already satisfied: frozenlist in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from ray[rllib]) (1.3.1)\n",
            "Requirement already satisfied: click<=8.0.4,>=7.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from ray[rllib]) (8.0.4)\n",
            "Requirement already satisfied: attrs in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from ray[rllib]) (22.1.0)\n",
            "Requirement already satisfied: virtualenv in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from ray[rllib]) (20.16.6)\n",
            "Requirement already satisfied: scikit-image in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from ray[rllib]) (0.19.3)\n",
            "Requirement already satisfied: matplotlib!=3.4.3 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from ray[rllib]) (3.6.1)\n",
            "Requirement already satisfied: dm-tree in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from ray[rllib]) (0.1.7)\n",
            "Requirement already satisfied: tabulate in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from ray[rllib]) (0.9.0)\n",
            "Requirement already satisfied: gym<0.24.0,>=0.21.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from ray[rllib]) (0.21.0)\n",
            "Requirement already satisfied: scipy in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from ray[rllib]) (1.9.3)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from ray[rllib]) (2.5.1)\n",
            "Requirement already satisfied: pandas in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from ray[rllib]) (1.5.1)\n",
            "Requirement already satisfied: lz4 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from ray[rllib]) (4.0.2)\n",
            "Requirement already satisfied: six>=1.5.2 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from grpcio<=1.43.0,>=1.42.0->ray[rllib]) (1.16.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from gym<0.24.0,>=0.21.0->ray[rllib]) (2.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from matplotlib!=3.4.3->ray[rllib]) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from matplotlib!=3.4.3->ray[rllib]) (1.0.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from matplotlib!=3.4.3->ray[rllib]) (9.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from matplotlib!=3.4.3->ray[rllib]) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from matplotlib!=3.4.3->ray[rllib]) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from matplotlib!=3.4.3->ray[rllib]) (4.38.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from matplotlib!=3.4.3->ray[rllib]) (21.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from matplotlib!=3.4.3->ray[rllib]) (1.4.4)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from jsonschema->ray[rllib]) (0.18.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from pandas->ray[rllib]) (2022.5)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from requests->ray[rllib]) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from requests->ray[rllib]) (2022.9.24)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from requests->ray[rllib]) (2.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from requests->ray[rllib]) (1.26.12)\n",
            "Requirement already satisfied: networkx>=2.2 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from scikit-image->ray[rllib]) (2.8.7)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from scikit-image->ray[rllib]) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from scikit-image->ray[rllib]) (2022.10.10)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from scikit-image->ray[rllib]) (2.22.2)\n",
            "Requirement already satisfied: platformdirs<3,>=2.4 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from virtualenv->ray[rllib]) (2.5.2)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from virtualenv->ray[rllib]) (0.3.6)\n",
            "Requirement already satisfied: opencv-python in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from opencv-python) (1.23.4)\n"
          ]
        }
      ],
      "source": [
        "# We install these specific versions of tensorflow and rllib, that we used in our work.\n",
        "!pip install gym>=0.21\n",
        "!pip install tensorflow>=1.14\n",
        "# !pip install \"ray[rllib]==0.8.4\"\n",
        "!pip install \"ray[rllib]\"\n",
        "!pip install opencv-python\n",
        "!pip install opencv-python-headless>=4.1.2.30\n",
        "!pip install aiohttp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting opencensus\n",
            "  Downloading opencensus-0.11.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting google-api-core<3.0.0,>=1.0.0\n",
            "  Downloading google_api_core-2.10.2-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.6/115.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencensus-context>=0.1.3\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus) (2.13.0)\n",
            "Collecting googleapis-common-protos<2.0dev,>=1.56.2\n",
            "  Downloading googleapis_common_protos-1.56.4-py2.py3-none-any.whl (211 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.7/211.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus) (2.28.1)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus) (3.19.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus) (4.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0,>=1.0.0->opencensus) (2.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0,>=1.0.0->opencensus) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0,>=1.0.0->opencensus) (2022.9.24)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0,>=1.0.0->opencensus) (3.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus) (0.4.8)\n",
            "Installing collected packages: opencensus-context, googleapis-common-protos, google-api-core, opencensus\n",
            "Successfully installed google-api-core-2.10.2 googleapis-common-protos-1.56.4 opencensus-0.11.0 opencensus-context-0.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install opencensus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting aiohttp_cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: aiohttp>=1.1 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from aiohttp_cors) (3.8.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from aiohttp>=1.1->aiohttp_cors) (1.8.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from aiohttp>=1.1->aiohttp_cors) (6.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from aiohttp>=1.1->aiohttp_cors) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from aiohttp>=1.1->aiohttp_cors) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from aiohttp>=1.1->aiohttp_cors) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from aiohttp>=1.1->aiohttp_cors) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from aiohttp>=1.1->aiohttp_cors) (22.1.0)\n",
            "Requirement already satisfied: idna>=2.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp>=1.1->aiohttp_cors) (3.4)\n",
            "Installing collected packages: aiohttp_cors\n",
            "Successfully installed aiohttp_cors-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install aiohttp_cors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_aEzYs7rQbs",
        "outputId": "1bcce49f-f5b5-4cce-cc16-2702eee0c562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rl-warp-drive\n",
            "  Using cached rl_warp_drive-2.0.2-py3-none-any.whl (381 kB)\n",
            "Requirement already satisfied: gym<0.26,>=0.18 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from rl-warp-drive) (0.21.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from rl-warp-drive) (1.23.4)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from rl-warp-drive) (6.0)\n",
            "  Using cached rl_warp_drive-2.0.1-py3-none-any.whl (375 kB)\n",
            "  Using cached rl_warp_drive-2.0-py3-none-any.whl (375 kB)\n",
            "  Using cached rl_warp_drive-1.7.0-py3-none-any.whl (336 kB)\n",
            "  Using cached rl_warp_drive-1.6.7-py3-none-any.whl (336 kB)\n",
            "Collecting pycuda==2021.1\n",
            "  Using cached pycuda-2021.1.tar.gz (1.7 MB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting rl-warp-drive\n",
            "  Using cached rl_warp_drive-1.6.5-py3-none-any.whl (323 kB)\n",
            "  Using cached rl_warp_drive-1.6.4-py3-none-any.whl (121 kB)\n",
            "  Using cached rl_warp_drive-1.6.3-py3-none-any.whl (121 kB)\n",
            "  Using cached rl_warp_drive-1.6.2-py3-none-any.whl (121 kB)\n",
            "Requirement already satisfied: pytest>=6.1.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from rl-warp-drive) (7.2.0)\n",
            "  Using cached rl_warp_drive-1.6.1-py3-none-any.whl (121 kB)\n",
            "Collecting torch>=1.9.0\n",
            "  Using cached torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n",
            "Requirement already satisfied: matplotlib>=3.2.1 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from rl-warp-drive) (3.6.1)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from pycuda==2021.1->rl-warp-drive) (1.4.4)\n",
            "Requirement already satisfied: pytools>=2011.2 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from pycuda==2021.1->rl-warp-drive) (2022.1.12)\n",
            "Requirement already satisfied: mako in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from pycuda==2021.1->rl-warp-drive) (1.2.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from gym<0.26,>=0.18->rl-warp-drive) (2.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from matplotlib>=3.2.1->rl-warp-drive) (1.0.5)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from matplotlib>=3.2.1->rl-warp-drive) (3.0.9)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from matplotlib>=3.2.1->rl-warp-drive) (9.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from matplotlib>=3.2.1->rl-warp-drive) (21.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from matplotlib>=3.2.1->rl-warp-drive) (4.38.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from matplotlib>=3.2.1->rl-warp-drive) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from matplotlib>=3.2.1->rl-warp-drive) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from matplotlib>=3.2.1->rl-warp-drive) (2.8.2)\n",
            "Requirement already satisfied: iniconfig in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from pytest>=6.1.0->rl-warp-drive) (1.1.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from pytest>=6.1.0->rl-warp-drive) (2.0.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from pytest>=6.1.0->rl-warp-drive) (1.0.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from pytest>=6.1.0->rl-warp-drive) (22.1.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from pytest>=6.1.0->rl-warp-drive) (1.0.0rc9)\n",
            "Requirement already satisfied: typing-extensions in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from torch>=1.9.0->rl-warp-drive) (4.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.2.1->rl-warp-drive) (1.16.0)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from pytools>=2011.2->pycuda==2021.1->rl-warp-drive) (2.5.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from mako->pycuda==2021.1->rl-warp-drive) (2.1.1)\n",
            "Building wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pycuda \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[134 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m *************************************************************\n",
            "  \u001b[31m   \u001b[0m *** I have detected that you have not run configure.py.\n",
            "  \u001b[31m   \u001b[0m *************************************************************\n",
            "  \u001b[31m   \u001b[0m *** Additionally, no global config files were found.\n",
            "  \u001b[31m   \u001b[0m *** I will go ahead with the default configuration.\n",
            "  \u001b[31m   \u001b[0m *** In all likelihood, this will not work out.\n",
            "  \u001b[31m   \u001b[0m ***\n",
            "  \u001b[31m   \u001b[0m *** See README_SETUP.txt for more information.\n",
            "  \u001b[31m   \u001b[0m ***\n",
            "  \u001b[31m   \u001b[0m *** If the build does fail, just re-run configure.py with the\n",
            "  \u001b[31m   \u001b[0m *** correct arguments, and then retry. Good luck!\n",
            "  \u001b[31m   \u001b[0m *************************************************************\n",
            "  \u001b[31m   \u001b[0m *** HIT Ctrl-C NOW IF THIS IS NOT WHAT YOU WANT\n",
            "  \u001b[31m   \u001b[0m *************************************************************\n",
            "  \u001b[31m   \u001b[0m Continuing in 10 seconds...\n",
            "  \u001b[31m   \u001b[0m Continuing in 9 seconds...\n",
            "  \u001b[31m   \u001b[0m Continuing in 8 seconds...\n",
            "  \u001b[31m   \u001b[0m Continuing in 7 seconds...\n",
            "  \u001b[31m   \u001b[0m Continuing in 6 seconds...\n",
            "  \u001b[31m   \u001b[0m Continuing in 5 seconds...\n",
            "  \u001b[31m   \u001b[0m Continuing in 4 seconds...\n",
            "  \u001b[31m   \u001b[0m Continuing in 3 seconds...\n",
            "  \u001b[31m   \u001b[0m Continuing in 2 seconds...\n",
            "  \u001b[31m   \u001b[0m Continuing in 1 seconds...\n",
            "  \u001b[31m   \u001b[0m /tmp/pip-build-env-n9zi9sqe/overlay/lib/python3.10/site-packages/setuptools/_distutils/dist.py:264: UserWarning: Unknown distribution option: 'test_requires'\n",
            "  \u001b[31m   \u001b[0m   warnings.warn(msg)\n",
            "  \u001b[31m   \u001b[0m running bdist_wheel\n",
            "  \u001b[31m   \u001b[0m running build\n",
            "  \u001b[31m   \u001b[0m running build_py\n",
            "  \u001b[31m   \u001b[0m creating build\n",
            "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310\n",
            "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/pycuda\n",
            "  \u001b[31m   \u001b[0m copying pycuda/cumath.py -> build/lib.linux-x86_64-cpython-310/pycuda\n",
            "  \u001b[31m   \u001b[0m copying pycuda/_mymako.py -> build/lib.linux-x86_64-cpython-310/pycuda\n",
            "  \u001b[31m   \u001b[0m copying pycuda/debug.py -> build/lib.linux-x86_64-cpython-310/pycuda\n",
            "  \u001b[31m   \u001b[0m copying pycuda/curandom.py -> build/lib.linux-x86_64-cpython-310/pycuda\n",
            "  \u001b[31m   \u001b[0m copying pycuda/autoinit.py -> build/lib.linux-x86_64-cpython-310/pycuda\n",
            "  \u001b[31m   \u001b[0m copying pycuda/reduction.py -> build/lib.linux-x86_64-cpython-310/pycuda\n",
            "  \u001b[31m   \u001b[0m copying pycuda/autoprimaryctx.py -> build/lib.linux-x86_64-cpython-310/pycuda\n",
            "  \u001b[31m   \u001b[0m copying pycuda/characterize.py -> build/lib.linux-x86_64-cpython-310/pycuda\n",
            "  \u001b[31m   \u001b[0m copying pycuda/_cluda.py -> build/lib.linux-x86_64-cpython-310/pycuda\n",
            "  \u001b[31m   \u001b[0m copying pycuda/driver.py -> build/lib.linux-x86_64-cpython-310/pycuda\n",
            "  \u001b[31m   \u001b[0m copying pycuda/elementwise.py -> build/lib.linux-x86_64-cpython-310/pycuda\n",
            "  \u001b[31m   \u001b[0m copying pycuda/tools.py -> build/lib.linux-x86_64-cpython-310/pycuda\n",
            "  \u001b[31m   \u001b[0m copying pycuda/gpuarray.py -> build/lib.linux-x86_64-cpython-310/pycuda\n",
            "  \u001b[31m   \u001b[0m copying pycuda/__init__.py -> build/lib.linux-x86_64-cpython-310/pycuda\n",
            "  \u001b[31m   \u001b[0m copying pycuda/scan.py -> build/lib.linux-x86_64-cpython-310/pycuda\n",
            "  \u001b[31m   \u001b[0m copying pycuda/compiler.py -> build/lib.linux-x86_64-cpython-310/pycuda\n",
            "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/pycuda/gl\n",
            "  \u001b[31m   \u001b[0m copying pycuda/gl/autoinit.py -> build/lib.linux-x86_64-cpython-310/pycuda/gl\n",
            "  \u001b[31m   \u001b[0m copying pycuda/gl/__init__.py -> build/lib.linux-x86_64-cpython-310/pycuda/gl\n",
            "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/pycuda/sparse\n",
            "  \u001b[31m   \u001b[0m copying pycuda/sparse/inner.py -> build/lib.linux-x86_64-cpython-310/pycuda/sparse\n",
            "  \u001b[31m   \u001b[0m copying pycuda/sparse/pkt_build.py -> build/lib.linux-x86_64-cpython-310/pycuda/sparse\n",
            "  \u001b[31m   \u001b[0m copying pycuda/sparse/coordinate.py -> build/lib.linux-x86_64-cpython-310/pycuda/sparse\n",
            "  \u001b[31m   \u001b[0m copying pycuda/sparse/packeted.py -> build/lib.linux-x86_64-cpython-310/pycuda/sparse\n",
            "  \u001b[31m   \u001b[0m copying pycuda/sparse/cg.py -> build/lib.linux-x86_64-cpython-310/pycuda/sparse\n",
            "  \u001b[31m   \u001b[0m copying pycuda/sparse/operator.py -> build/lib.linux-x86_64-cpython-310/pycuda/sparse\n",
            "  \u001b[31m   \u001b[0m copying pycuda/sparse/__init__.py -> build/lib.linux-x86_64-cpython-310/pycuda/sparse\n",
            "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/pycuda/compyte\n",
            "  \u001b[31m   \u001b[0m copying pycuda/compyte/array.py -> build/lib.linux-x86_64-cpython-310/pycuda/compyte\n",
            "  \u001b[31m   \u001b[0m copying pycuda/compyte/dtypes.py -> build/lib.linux-x86_64-cpython-310/pycuda/compyte\n",
            "  \u001b[31m   \u001b[0m copying pycuda/compyte/__init__.py -> build/lib.linux-x86_64-cpython-310/pycuda/compyte\n",
            "  \u001b[31m   \u001b[0m running egg_info\n",
            "  \u001b[31m   \u001b[0m writing pycuda.egg-info/PKG-INFO\n",
            "  \u001b[31m   \u001b[0m writing dependency_links to pycuda.egg-info/dependency_links.txt\n",
            "  \u001b[31m   \u001b[0m writing requirements to pycuda.egg-info/requires.txt\n",
            "  \u001b[31m   \u001b[0m writing top-level names to pycuda.egg-info/top_level.txt\n",
            "  \u001b[31m   \u001b[0m reading manifest file 'pycuda.egg-info/SOURCES.txt'\n",
            "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
            "  \u001b[31m   \u001b[0m warning: no files found matching 'doc/source/_static/*.css'\n",
            "  \u001b[31m   \u001b[0m warning: no files found matching 'doc/source/_templates/*.html'\n",
            "  \u001b[31m   \u001b[0m warning: no files found matching '*.cpp' under directory 'bpl-subset/bpl_subset/boost'\n",
            "  \u001b[31m   \u001b[0m warning: no files found matching '*.html' under directory 'bpl-subset/bpl_subset/boost'\n",
            "  \u001b[31m   \u001b[0m warning: no files found matching '*.inl' under directory 'bpl-subset/bpl_subset/boost'\n",
            "  \u001b[31m   \u001b[0m warning: no files found matching '*.txt' under directory 'bpl-subset/bpl_subset/boost'\n",
            "  \u001b[31m   \u001b[0m warning: no files found matching '*.h' under directory 'bpl-subset/bpl_subset/libs'\n",
            "  \u001b[31m   \u001b[0m warning: no files found matching '*.ipp' under directory 'bpl-subset/bpl_subset/libs'\n",
            "  \u001b[31m   \u001b[0m warning: no files found matching '*.pl' under directory 'bpl-subset/bpl_subset/libs'\n",
            "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
            "  \u001b[31m   \u001b[0m writing manifest file 'pycuda.egg-info/SOURCES.txt'\n",
            "  \u001b[31m   \u001b[0m /tmp/pip-build-env-n9zi9sqe/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'pycuda.cuda' as data is deprecated, please list it in `packages`.\n",
            "  \u001b[31m   \u001b[0m     !!\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m     ############################\n",
            "  \u001b[31m   \u001b[0m     # Package would be ignored #\n",
            "  \u001b[31m   \u001b[0m     ############################\n",
            "  \u001b[31m   \u001b[0m     Python recognizes 'pycuda.cuda' as an importable package,\n",
            "  \u001b[31m   \u001b[0m     but it is not listed in the `packages` configuration of setuptools.\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m     'pycuda.cuda' has been automatically added to the distribution only\n",
            "  \u001b[31m   \u001b[0m     because it may contain data files, but this behavior is likely to change\n",
            "  \u001b[31m   \u001b[0m     in future versions of setuptools (and therefore is considered deprecated).\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m     Please make sure that 'pycuda.cuda' is included as a package by using\n",
            "  \u001b[31m   \u001b[0m     the `packages` configuration field or the proper discovery methods\n",
            "  \u001b[31m   \u001b[0m     (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "  \u001b[31m   \u001b[0m     instead of `find_packages(...)`/`find:`).\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m     You can read more about \"package discovery\" and \"data files\" on setuptools\n",
            "  \u001b[31m   \u001b[0m     documentation page.\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m !!\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
            "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/pycuda/cuda\n",
            "  \u001b[31m   \u001b[0m copying pycuda/cuda/pycuda-complex-impl.hpp -> build/lib.linux-x86_64-cpython-310/pycuda/cuda\n",
            "  \u001b[31m   \u001b[0m copying pycuda/cuda/pycuda-complex.hpp -> build/lib.linux-x86_64-cpython-310/pycuda/cuda\n",
            "  \u001b[31m   \u001b[0m copying pycuda/cuda/pycuda-helpers.hpp -> build/lib.linux-x86_64-cpython-310/pycuda/cuda\n",
            "  \u001b[31m   \u001b[0m copying pycuda/sparse/pkt_build_cython.pyx -> build/lib.linux-x86_64-cpython-310/pycuda/sparse\n",
            "  \u001b[31m   \u001b[0m running build_ext\n",
            "  \u001b[31m   \u001b[0m building '_driver' extension\n",
            "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310\n",
            "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310/bpl-subset\n",
            "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310/bpl-subset/bpl_subset\n",
            "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310/bpl-subset/bpl_subset/libs\n",
            "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310/bpl-subset/bpl_subset/libs/python\n",
            "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310/bpl-subset/bpl_subset/libs/python/src\n",
            "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310/bpl-subset/bpl_subset/libs/python/src/converter\n",
            "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310/bpl-subset/bpl_subset/libs/python/src/object\n",
            "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310/bpl-subset/bpl_subset/libs/smart_ptr\n",
            "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310/bpl-subset/bpl_subset/libs/smart_ptr/src\n",
            "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310/bpl-subset/bpl_subset/libs/system\n",
            "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310/bpl-subset/bpl_subset/libs/system/src\n",
            "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310/bpl-subset/bpl_subset/libs/thread\n",
            "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310/bpl-subset/bpl_subset/libs/thread/src\n",
            "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310/bpl-subset/bpl_subset/libs/thread/src/pthread\n",
            "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310/src\n",
            "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310/src/cpp\n",
            "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310/src/wrapper\n",
            "  \u001b[31m   \u001b[0m gcc -pthread -B /home/supremusdominus/anaconda3/envs/ML/compiler_compat -Wno-unused-result -Wsign-compare -fwrapv -Wall -O3 -DNDEBUG -fPIC -DBOOST_ALL_NO_LIB=1 -DBOOST_THREAD_BUILD_DLL=1 -DBOOST_MULTI_INDEX_DISABLE_SERIALIZATION=1 -DBOOST_PYTHON_SOURCE=1 -Dboost=pycudaboost -DBOOST_THREAD_DONT_USE_CHRONO=1 -DPYGPU_PACKAGE=pycuda -DPYGPU_PYCUDA=1 -DHAVE_CURAND=1 -Isrc/cpp -Ibpl-subset/bpl_subset \"-I/mnt/c/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.7/include\" -I/tmp/pip-build-env-n9zi9sqe/overlay/lib/python3.10/site-packages/numpy/core/include -I/home/supremusdominus/anaconda3/envs/ML/include/python3.10 -c bpl-subset/bpl_subset/libs/python/src/converter/arg_to_python_base.cpp -o build/temp.linux-x86_64-cpython-310/bpl-subset/bpl_subset/libs/python/src/converter/arg_to_python_base.o\n",
            "  \u001b[31m   \u001b[0m error: command 'gcc' failed: No such file or directory\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for pycuda\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build pycuda\n",
            "\u001b[31mERROR: Could not build wheels for pycuda, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install rl-warp-drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XXSxlt02KslN"
      },
      "outputs": [],
      "source": [
        "# Change directory to the tutorials folder\n",
        "import os, sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    os.chdir(\"/content/ai-economist/tutorials\")\n",
        "else:\n",
        "    os.chdir(os.path.dirname(os.path.abspath(\"__file__\"))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0ptmCDPKslN"
      },
      "source": [
        "## 1. Adding an Environment Wrapper "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56yP4q3zKslN"
      },
      "source": [
        "We first define a configuration (introduced in [the basics tutorial](https://github.com/salesforce/ai-economist/blob/master/tutorials/economic_simulation_basics.ipynb)) for the \"gather-trade-build\" environment with multiple mobile agents (that move, gather resources, build or trade) and a social planner that sets taxes according to (a scaled variant of) the 2018 US tax schedule."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_YcfRA8NuAXN"
      },
      "outputs": [],
      "source": [
        "env_config_dict = {\n",
        "    # Scenario name - determines which scenario class to use\n",
        "    \"scenario_name\": \"CovidAndEconomySimulation\",\n",
        "    \n",
        "    # The list of components in this simulation\n",
        "    \"components\": [\n",
        "        {\"ControlUSStateOpenCloseStatus\": {\n",
        "            # action cooldown period in days.\n",
        "            # Once a stringency level is set, the state(s) cannot switch to another level\n",
        "            # for a certain number of days (referred to as the \"action_cooldown_period\")\n",
        "            \"action_cooldown_period\": 28\n",
        "        }},\n",
        "        {\"FederalGovernmentSubsidy\": {\n",
        "            # The number of subsidy levels.\n",
        "            \"num_subsidy_levels\": 20,\n",
        "            # The number of days over which the total subsidy amount is evenly rolled out.\n",
        "            \"subsidy_interval\": 90,\n",
        "            # The maximum annual subsidy that may be allocated per person.\n",
        "            \"max_annual_subsidy_per_person\": 20000,\n",
        "        }},\n",
        "        {\"VaccinationCampaign\": {\n",
        "            # The number of vaccines available per million people everyday.\n",
        "            \"daily_vaccines_per_million_people\": 3000,\n",
        "            # The number of days between vaccine deliveries.\n",
        "            \"delivery_interval\": 1,\n",
        "            # The date (YYYY-MM-DD) when vaccination begins\n",
        "            \"vaccine_delivery_start_date\": \"2021-01-12\",\n",
        "        }},\n",
        "        {\"FederalQuantitativeEasing\": {\n",
        "            # The number of QE levels.\n",
        "            \"num_QE_levels\": 20,\n",
        "            # The number of days over which the total subsidy amount is evenly rolled out.\n",
        "            \"QE_interval\": 90,\n",
        "            # The maximum annual subsidy that may be allocated per person.\n",
        "            \"max_annual_QE_per_person\": 20\n",
        "        }},\n",
        "    ],\n",
        "\n",
        "    # Date (YYYY-MM-DD) to start the simulation.\n",
        "    \"start_date\": \"2020-03-22\",\n",
        "    # How long to run the simulation for (in days)\n",
        "    \"episode_length\": 405,\n",
        "    \n",
        "    # use_real_world_data (bool): Replay what happened in the real world.\n",
        "    # Real-world data comprises SIR (susceptible/infected/recovered),\n",
        "    # unemployment, government policy, and vaccination numbers.\n",
        "    # This setting also sets use_real_world_policies=True.\n",
        "    \"use_real_world_data\": False,\n",
        "    # use_real_world_policies (bool): Run the environment with real-world policies\n",
        "    # (stringency levels and subsidies). With this setting and\n",
        "    # use_real_world_data=False, SIR and economy dynamics are still\n",
        "    # driven by fitted models.\n",
        "    \"use_real_world_policies\": False,\n",
        "    \n",
        "    # A factor indicating how much more the\n",
        "    # states prioritize health (roughly speaking, loss of lives due to\n",
        "    # opening up more) over the economy (roughly speaking, a loss in GDP\n",
        "    # due to shutting down resulting in more unemployment) compared to the\n",
        "    # real-world.\n",
        "    # For example, a value of 1 corresponds to the health weight that \n",
        "    # maximizes social welfare under the real-world policy, while\n",
        "    # a value of 2 means that states care twice as much about public health\n",
        "    # (preventing deaths), while a value of 0.5 means that states care twice\n",
        "    # as much about the economy (preventing GDP drops).\n",
        "    \"health_priority_scaling_agents\": 1,\n",
        "    # Same as above for the planner\n",
        "    \"health_priority_scaling_planner\": 1,\n",
        "    \n",
        "    # Full path to the directory containing\n",
        "    # the data, fitted parameters and model constants. This defaults to\n",
        "    # \"ai_economist/datasets/covid19_datasets/data_and_fitted_params\".\n",
        "    # For details on obtaining these parameters, please see the notebook\n",
        "    # \"ai-economist-foundation/ai_economist/datasets/covid19_datasets/\n",
        "    # gather_real_world_data_and_fit_parameters.ipynb\".\n",
        "    \"path_to_data_and_fitted_params\": \"\",\n",
        "    \n",
        "    # Economy-related parameters\n",
        "    # Fraction of people infected with COVID-19. Infected people don't work.\n",
        "    \"infection_too_sick_to_work_rate\": 0.1,\n",
        "    # Fraction of the population between ages 18-65.\n",
        "    # This is the subset of the population whose employment/unemployment affects\n",
        "    # economic productivity.\n",
        "    \"pop_between_age_18_65\": 0.6,\n",
        "    # Percentage of interest paid by the federal\n",
        "    # government to borrow money from the federal reserve for COVID-19 relief\n",
        "    # (direct payments). Higher interest rates mean that direct payments\n",
        "    # have a larger cost on the federal government's economic index.\n",
        "    \"risk_free_interest_rate\": 0.03,\n",
        "    # CRRA eta parameter for modeling the economic reward non-linearity.\n",
        "    \"economic_reward_crra_eta\": 2,\n",
        "       \n",
        "    # Number of agents in the simulation (50 US states + Washington DC)\n",
        "    \"n_agents\": 51,    \n",
        "    # World size: Not relevant to this simulation, but needs to be set for Foundation\n",
        "    \"world_size\": [1, 1],\n",
        "    # Flag to collate all the agents' observations, rewards and done flags into a single matrix\n",
        "    \"collate_agent_step_and_reset_data\": True,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37_c6yeUKslO"
      },
      "source": [
        "Like we have seen in earlier [tutorials](https://github.com/salesforce/ai-economist/blob/master/tutorials/economic_simulation_basic.ipynb), using `env = foundation.make_env_instance(**env_config)` creates an environment instance `env` with the specified configuration.\n",
        "\n",
        "In order to use this environment with RLlib, we will also need to add the environment's `observation_space` and `action_space` attributes. Additionally, the environment itself must subclass the [`MultiAgentEnv`](https://github.com/ray-project/ray/blob/master/rllib/env/multi_agent_env.py) interface, which can return observations and rewards from multiple ready agents per step. To this end, we use an environment [wrapper](https://github.com/salesforce/ai-economist/blob/master/tutorials/rllib/env_wrapper.py)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "t73kIcDSKslO",
        "outputId": "7dd06121-f616-4ff4-b04d-15ee76408443"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inside covid19_components.py: 1 GPUs are available.\n",
            "Warning: The 'WarpDrive' package is not found and cannot be used! If you wish to use WarpDrive, please run 'pip install rl-warp-drive' first.\n",
            "Inside covid19_components.py: 0 GPUs are available.\n",
            "No GPUs found! Running the simulation on a CPU.\n",
            "Inside covid19_env.py: 0 GPUs are available.\n",
            "No GPUs found! Running the simulation on a CPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:No traceback has been produced, nothing to debug.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using the real-world data to only initialize the env, and using the fitted models to step through the env.\n",
            "Loading real-world data from /home/supremusdominus/Download/ai-economist/ai_economist/foundation/scenarios/covid19/../../../datasets/covid19_datasets/data_and_fitted_params\n",
            "Loading fit parameters from /home/supremusdominus/Download/ai-economist/ai_economist/foundation/scenarios/covid19/../../../datasets/covid19_datasets/data_and_fitted_params\n",
            "Using external action inputs.\n",
            "[EnvWrapper] Spaces\n",
            "[EnvWrapper] Obs (a)   \n",
            "action_mask    : (11, 51)\n",
            "flat           : (357,)\n",
            "time           : (51,)\n",
            "world-agent_index: (51, 51)\n",
            "world-agent_state: (6, 51)\n",
            "\n",
            "\n",
            "[EnvWrapper] Obs (p)   \n",
            "action_mask    : (21,)\n",
            "flat           : (259,)\n",
            "time           : (1,)\n",
            "world-agent_state: (6, 51)\n",
            "\n",
            "\n",
            "[EnvWrapper] Obs (f)   \n",
            "action_mask    : (21,)\n",
            "flat           : (207,)\n",
            "time           : (1,)\n",
            "world-agent_state: (6, 51)\n",
            "\n",
            "\n",
            "[EnvWrapper] Action (a) Discrete(11)\n",
            "[EnvWrapper] Action (p) MultiDiscrete([21])\n"
          ]
        }
      ],
      "source": [
        "from rllib.env_wrapper import Covid19RLlibEnvWrapper\n",
        "%debug\n",
        "env_obj = Covid19RLlibEnvWrapper({\"env_config_dict\": env_config_dict}, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIve5a8XKslP"
      },
      "source": [
        "Upon applying the wrapper to our environment, we have now defined observation and action spaces for the agents and the planner, indicated with `(a)` and `(p)` respectively. Also, (a useful tip) you can still access the environment instance and its attributes simply by using `env_obj.env`\n",
        "\n",
        "In summary, the observation spaces are represented as `Box` objects and the action spaces as `Discrete` objects (for more details on these types, see the OpenAI documentation [page](https://gym.openai.com/docs/#spaces)).\n",
        "\n",
        "Briefly looking at the shapes of the observation features (the numbers in parentheses), you will see that we have some one-dimensional features (e.g. `action-mask`, `flat`, `time`) as well as spatial features (e.g., `world-idx-map`, `world-map`)\n",
        "\n",
        "A couple of quick notes:\n",
        "- An `action_mask` is used to mask out the actions that are not allowed by the environment. For instance, a mobile agent cannot move beyond the boundary of the world. Hence, in position (0, 0), a mobile cannot move \"Left\" or \"Down\", and the corresponding actions in the mask would be nulled out. Now, the RL agent can still recommend to move \"Left\" or \"Down\", but the action isn't really taken.\n",
        "- The key `flat` arises since we set `flatten_observations': True`. Accordingly, the scalar and vector raw observations are all concatenated into this single key. If you're curious to see the entire set of raw observations, do set `flatten_observations': False` in the env_config, and re-run the above cell.\n",
        "\n",
        "Looking at the action spaces, the mobile agents can take 50 possible actions (including 1 NO-OP action or do nothing (always indexed 0), 44 trading-related actions, 4 move actions along the four directions and 1 build action)\n",
        "\n",
        "The planner sets the tax rates for 7 brackets, each from 0-100% in steps of 5%, so that's 21 values. Adding the NO-OP action brings the planner action space to `MultiDiscrete([22 22 22 22 22 22 22])`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lIr7PJBKslP"
      },
      "source": [
        "## 2. Creating a *Trainer* Object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bjMXlsHKslP"
      },
      "source": [
        "In order to train our economic simulation environment with RLlib, you will need familiarity with one of the key classes: the [`Trainer`](https://docs.ray.io/en/master/rllib-training.html). The trainer object maintains the relationships that connect each agent in the environment to its corresponding trainable policy, and essentially helps in training, checkpointing policies and inferring actions. It helps to co-ordinate the workflow of collecting rollouts and optimizing the various policies via a reinforcement learning algorithm. Inherently, RLlib maintains a wide suite of [algorithms](https://docs.ray.io/en/master/rllib-algorithms.html) for multi-agent learning (which was another strong reason for us to consider using RLlib) - available options include SAC, PPO, PG, A2C, A3C, IMPALA, ES, DDPG, DQN, MARWIL, APEX, and APEX_DDPG. For the remainder of this tutorial, we will stick to using [Proximal Policy Optimization](https://openai.com/blog/openai-baselines-ppo/) (PPO), an algorithm known to perform well generally.\n",
        "\n",
        "Every algorithm has a corresponding trainer object; in the context of PPO, we invoke the `PPOTrainer` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-WiojcJ-KslP"
      },
      "outputs": [],
      "source": [
        "import ray\n",
        "from ray.rllib.agents.ppo import PPOTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv8bKQIkKslP"
      },
      "source": [
        "PPOTrainer can be instantiated with \n",
        "- `env`: an environment creator (i.e, RLlibEnvWrapper() in our case)\n",
        "- `config`: algorithm-specific configuration data for setting the various components of the RL training loop including the environment, rollout worker processes, training resources, degree of parallelism, framework used, and the policy exploration strategies.\n",
        "\n",
        "Note: There are several configuration settings related to policy architectures, rollout collection, minibatching, and other important hyperparameters, that need to be set carefully in order to train effectively. For the sake of the high-level exposition, we allow RLlib to use most of the the default settings. Check out the list of default [common configuration parameters](https://docs.ray.io/en/releases-0.8.4/rllib-training.html#common-parameters) and default [PPO-specific configuration parameters](https://docs.ray.io/en/releases-0.8.4/rllib-algorithms.html?highlight=PPO#proximal-policy-optimization-ppo). Custom environment configurations may be passed to environment creator via `config[\"env_config\"]`.\n",
        "\n",
        "RLlib also chooses default built-in [models](https://docs.ray.io/en/releases-0.8.4/rllib-models.html#built-in-models-and-preprocessors) for processing the observations. The models are picked based on a simple heuristic: a [vision](https://github.com/ray-project/ray/blob/master/rllib/models/tf/visionnet.py) network for observations that have shape of length larger than 2 (for example, (84 x 84 x 3)), and a [fully connected](https://github.com/ray-project/ray/blob/master/rllib/models/tf/fcnet.py) network for everything else. Custom models can be configured via the `config[\"policy\"][\"model\"]` key.\n",
        "\n",
        "In the context of multi-agent training, we will also need to set the multi-agent configuration:\n",
        "```python\n",
        "\"multiagent\": {\n",
        "        # Map of type MultiAgentPolicyConfigDict from policy ids to tuples\n",
        "        # of (policy_cls, obs_space, act_space, config). This defines the\n",
        "        # observation and action spaces of the policies and any extra config.\n",
        "        \"policies\": {},\n",
        "        # Function mapping agent ids to policy ids.\n",
        "        \"policy_mapping_fn\": None,\n",
        "        # Optional list of policies to train, or None for all policies.\n",
        "        \"policies_to_train\": None,\n",
        "    },\n",
        "```\n",
        "\n",
        "To this end, let's notate the agent policy id by `\"a\"` and the planner policy id by `\"p\"`. We can set `policies`, `policy_mapping_fun` and `policies_to_train` as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XNYtX4UgKslQ"
      },
      "outputs": [],
      "source": [
        "policies = {\n",
        "    \"a\": (\n",
        "        None,  # uses default policy\n",
        "        env_obj.observation_space,\n",
        "        env_obj.action_space,\n",
        "        {}  # define a custom agent policy configuration.\n",
        "    ),\n",
        "    \"p\": (\n",
        "        None,  # uses default policy\n",
        "        env_obj.observation_space_pl,\n",
        "        env_obj.action_space_pl,\n",
        "        {}  # define a custom planner policy configuration.\n",
        "    ),\n",
        "    \"f\": (\n",
        "        None,  # uses default policy\n",
        "        env_obj.observation_space_pl,\n",
        "        env_obj.action_space_pl,\n",
        "        {}  # define a custom planner policy configuration.\n",
        "    )\n",
        "}\n",
        "\n",
        "# In foundation, all the agents have integer ids and the social planner has an id of \"p\"\n",
        "policy_mapping_fun = lambda i: \"a\" if str(i).isdigit() else \"p\" if str(i) == \"p\" else \"f\"\n",
        "\n",
        "policies_to_train = [\"a\", \"p\", \"f\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To2aBqVkKslQ"
      },
      "source": [
        "Create a multiagent trainer config holding the trainable policies and their mappings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vGMZIVLlKslQ"
      },
      "outputs": [],
      "source": [
        "trainer_config = {\n",
        "    \"multiagent\": {\n",
        "        \"policies\": policies,\n",
        "        \"policies_to_train\": policies_to_train,\n",
        "        \"policy_mapping_fn\": policy_mapping_fun,\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlXDzKXVKslQ"
      },
      "source": [
        "With distributed RL, architectures typically comprise several **roll-out** and **trainer** workers operating in tandem\n",
        "![](assets/distributed_rl_architecture.png)\n",
        "\n",
        "The roll-out workers repeatedly step through the environment to generate and collect roll-outs in parallel, using the actions sampled from the policy models on the roll-out workers or provided by the trainer worker.\n",
        "Roll-out workers typically use CPU machines, and sometimes, GPU machines for richer environments.\n",
        "Trainer workers gather the roll-out data (asynchronously) from the roll-out workers and optimize policies on CPU or GPU machines.\n",
        "\n",
        "In this context, we can also add a `num_workers` configuration parameter to specify the number of rollout workers, i.e, those responsible for gathering rollouts. Note: setting `num_workers=0` will mean the rollouts will be collected by the trainer worker itself. Also, each worker can collect rollouts from multiple environments in parallel, which is specified in `num_envs_per_worker`; there will be a total of `num_workers` $\\times$ `num_envs_per_worker` environment replicas used to gather rollouts.\n",
        "Note: below, we also update some of the default trainer settings to keep the iteration time small."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "x4eet4q1KslQ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "trainer_config.update(\n",
        "    {\n",
        "        \"num_workers\": 1,\n",
        "        \"num_envs_per_worker\": 1,\n",
        "        # Other training parameters\n",
        "        \"train_batch_size\":  4000,\n",
        "        \"sgd_minibatch_size\": 4000,\n",
        "        \"num_sgd_iter\": 1\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ymw2yiAQKslR"
      },
      "source": [
        "Finally, we need to add the environment configuration to the trainer configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "xSmRLPb8KslR"
      },
      "outputs": [],
      "source": [
        "# We also add the \"num_envs_per_worker\" parameter for the env. wrapper to index the environments.\n",
        "env_config = {\n",
        "    \"env_config_dict\": env_config_dict,\n",
        "    \"num_envs_per_worker\": trainer_config.get('num_envs_per_worker'),   \n",
        "}\n",
        "\n",
        "trainer_config.update(\n",
        "    {\n",
        "        \"env_config\": env_config        \n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTToecbKKslR"
      },
      "source": [
        "One the training configuration is set, we will need to initialize ray and create the PPOTrainer object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QRqgCsdVKslR",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-10-31 02:29:13,272\tINFO worker.py:1518 -- Started a local Ray instance.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
              "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
              "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
              "            <g id=\"layer-1\">\n",
              "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
              "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
              "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
              "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
              "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
              "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
              "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
              "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
              "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
              "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
              "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
              "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
              "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
              "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
              "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
              "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
              "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
              "            </g>\n",
              "        </svg>\n",
              "        <table>\n",
              "            <tr>\n",
              "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
              "                <td style=\"text-align: left\"><b>3.10.4</b></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
              "                <td style=\"text-align: left\"><b> 2.0.1</b></td>\n",
              "            </tr>\n",
              "            \n",
              "        </table>\n",
              "    </div>\n",
              "</div>\n"
            ],
            "text/plain": [
              "RayContext(dashboard_url='', python_version='3.10.4', ray_version='2.0.1', ray_commit='03b6bc7b5a305877501110ec04710a9c57011479', address_info={'node_ip_address': '172.21.194.143', 'raylet_ip_address': '172.21.194.143', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-10-31_02-29-11_258072_2138/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-10-31_02-29-11_258072_2138/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2022-10-31_02-29-11_258072_2138', 'metrics_export_port': 47707, 'gcs_address': '172.21.194.143:42770', 'address': '172.21.194.143:42770', 'dashboard_agent_listen_port': 52365, 'node_id': '45a3c72b5016ec6c9066ac4c78847d514b6d8bb9142ac3bc14c2611f'})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize Ray\n",
        "# ray.init(webui_host=\"127.0.0.1\")\n",
        "ray.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======== Object references status: 2022-10-31 02:47:30.714665 ========\n",
            "Grouping by node address...        Sorting by object size...        Display allentries per group...\n",
            "\n",
            "\n",
            "--- Summary for node address: 172.21.194.143 ---\n",
            "Mem Used by Objects  Local References  Pinned        Used by task   Captured in Objects  Actor Handles\n",
            "5194.0 B             3, (5194.0 B)     0, (0.0 B)    0, (0.0 B)     0, (0.0 B)           3, (0.0 B)   \n",
            "\n",
            "--- Object references for node address: 172.21.194.143 ---\n",
            "IP Address    | PID      | Type    | Call Site | Status    | Size     | Reference Type | Object Ref\n",
            "\n",
            "172.21.194.143 | 2138     | Driver  | disabled  | FINISHED  | ?        | LOCAL_REFERENCE | 359ec6ce30d3ca2d11ab67d9e186d7c24774ec6c0100000001000000\n",
            "\n",
            "\n",
            "172.21.194.143 | 2138     | Driver  | disabled  | FINISHED  | ?        | ACTOR_HANDLE   | ffffffffffffffff4197a8feca610071f780d00c0100000001000000\n",
            "\n",
            "\n",
            "172.21.194.143 | 2138     | Driver  | disabled  | SCHEDULED | ?        | ACTOR_HANDLE   | ffffffffffffffff11ab67d9e186d7c24774ec6c0100000001000000\n",
            "\n",
            "\n",
            "172.21.194.143 | 2138     | Driver  | disabled  | FINISHED  | ?        | ACTOR_HANDLE   | ffffffffffffffff1902012e1b116d1035f9a71b0100000001000000\n",
            "\n",
            "\n",
            "172.21.194.143 | 2138     | Driver  | disabled  | FINISHED  | 15.0 B   | LOCAL_REFERENCE | 1e8ff6d2361327844197a8feca610071f780d00c0100000001000000\n",
            "\n",
            "\n",
            "172.21.194.143 | 2138     | Driver  | disabled  | FINISHED  | 5179.0 B | LOCAL_REFERENCE | d695f922effe6d991902012e1b116d1035f9a71b0100000001000000\n",
            "\n",
            "To record callsite information for each ObjectRef created, set env variable RAY_record_ref_creation_sites=1\n",
            "\n",
            "--- Aggregate object store stats across all nodes ---\n",
            "Plasma memory usage 0 MiB, 0 objects, 0.0% full, 0.0% needed\n",
            "\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!ray memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pydantic\n",
            "  Downloading pydantic-1.10.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.1.0 in /home/supremusdominus/anaconda3/envs/ML/lib/python3.10/site-packages (from pydantic) (4.4.0)\n",
            "Installing collected packages: pydantic\n",
            "Successfully installed pydantic-1.10.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pydantic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "nQ9v7BEHKslR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-10-31 02:48:52,861\tWARNING worker.py:1829 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffec593e54d3a0444c06203f0d01000000 Worker ID: 1a01288debea812d3f9b25226bf56fead842048ff4ef24f688c1b5a3 Node ID: 45a3c72b5016ec6c9066ac4c78847d514b6d8bb9142ac3bc14c2611f Worker IP address: 172.21.194.143 Worker port: 38373 Worker PID: 3449 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n"
          ]
        },
        {
          "ename": "RayActorError",
          "evalue": "The actor died unexpectedly before finishing this task.\n\tclass_name: RolloutWorker\n\tactor_id: ec593e54d3a0444c06203f0d01000000\n\tpid: 3449\n\tnamespace: d04a69c9-10c1-43e4-9346-de76743a5ac2\n\tip: 172.21.194.143\nThe actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\nThe actor never ran - it was cancelled before it started running.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRayActorError\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [35], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Create the PPO trainer.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mRAY_DISABLE_MEMORY_MONITOR\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m1\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m trainer \u001b[39m=\u001b[39m PPOTrainer(\n\u001b[1;32m      4\u001b[0m     env\u001b[39m=\u001b[39;49mCovid19RLlibEnvWrapper,\n\u001b[1;32m      5\u001b[0m     config\u001b[39m=\u001b[39;49mtrainer_config,\n\u001b[1;32m      6\u001b[0m     )\n",
            "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:312\u001b[0m, in \u001b[0;36mAlgorithm.__init__\u001b[0;34m(self, config, env, logger_creator, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39m# Initialize common evaluation_metrics to nan, before they become\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[39m# available. We want to make sure the metrics are always present\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[39m# (although their values may be nan), so that Tune does not complain\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[39m# when we use these as stopping criteria.\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_metrics \u001b[39m=\u001b[39m {\n\u001b[1;32m    305\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mevaluation\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[1;32m    306\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mepisode_reward_max\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mnan,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     }\n\u001b[1;32m    310\u001b[0m }\n\u001b[0;32m--> 312\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(config\u001b[39m=\u001b[39;49mconfig, logger_creator\u001b[39m=\u001b[39;49mlogger_creator, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    314\u001b[0m \u001b[39m# Check, whether `training_iteration` is still a tune.Trainable property\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[39m# and has not been overridden by the user in the attempt to implement the\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[39m# algos logic (this should be done now inside `training_step`).\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.10/site-packages/ray/tune/trainable/trainable.py:159\u001b[0m, in \u001b[0;36mTrainable.__init__\u001b[0;34m(self, config, logger_creator, remote_checkpoint_dir, custom_syncer, sync_timeout)\u001b[0m\n\u001b[1;32m    157\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_ip \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39mutil\u001b[39m.\u001b[39mget_node_ip_address()\n\u001b[0;32m--> 159\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup(copy\u001b[39m.\u001b[39;49mdeepcopy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig))\n\u001b[1;32m    160\u001b[0m setup_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m    161\u001b[0m \u001b[39mif\u001b[39;00m setup_time \u001b[39m>\u001b[39m SETUP_TIME_THRESHOLD:\n",
            "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:450\u001b[0m, in \u001b[0;36mAlgorithm.setup\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39margs[\u001b[39m2\u001b[39m]\n\u001b[1;32m    448\u001b[0m     \u001b[39m# In any other case, raise the RayActorError as-is.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 450\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    451\u001b[0m \u001b[39m# By default, collect metrics for all remote workers.\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_remote_workers_for_metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers\u001b[39m.\u001b[39mremote_workers()\n",
            "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:422\u001b[0m, in \u001b[0;36mAlgorithm.setup\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mif\u001b[39;00m _init \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     \u001b[39m# - Create rollout workers here automatically.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m     \u001b[39m# - Run the execution plan to create the local iterator to `next()`\u001b[39;00m\n\u001b[1;32m    418\u001b[0m     \u001b[39m#   in each training iteration.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m     \u001b[39m# This matches the behavior of using `build_trainer()`, which\u001b[39;00m\n\u001b[1;32m    420\u001b[0m     \u001b[39m# has been deprecated.\u001b[39;00m\n\u001b[1;32m    421\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 422\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers \u001b[39m=\u001b[39m WorkerSet(\n\u001b[1;32m    423\u001b[0m             env_creator\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv_creator,\n\u001b[1;32m    424\u001b[0m             validate_env\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalidate_env,\n\u001b[1;32m    425\u001b[0m             policy_class\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_default_policy_class(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig),\n\u001b[1;32m    426\u001b[0m             trainer_config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig,\n\u001b[1;32m    427\u001b[0m             num_workers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39mnum_workers\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    428\u001b[0m             local_worker\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    429\u001b[0m             logdir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogdir,\n\u001b[1;32m    430\u001b[0m         )\n\u001b[1;32m    431\u001b[0m     \u001b[39m# WorkerSet creation possibly fails, if some (remote) workers cannot\u001b[39;00m\n\u001b[1;32m    432\u001b[0m     \u001b[39m# be initialized properly (due to some errors in the RolloutWorker's\u001b[39;00m\n\u001b[1;32m    433\u001b[0m     \u001b[39m# constructor).\u001b[39;00m\n\u001b[1;32m    434\u001b[0m     \u001b[39mexcept\u001b[39;00m RayActorError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    435\u001b[0m         \u001b[39m# In case of an actor (remote worker) init failure, the remote worker\u001b[39;00m\n\u001b[1;32m    436\u001b[0m         \u001b[39m# may still exist and will be accessible, however, e.g. calling\u001b[39;00m\n\u001b[1;32m    437\u001b[0m         \u001b[39m# its `sample.remote()` would result in strange \"property not found\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m         \u001b[39m# errors.\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py:125\u001b[0m, in \u001b[0;36mWorkerSet.__init__\u001b[0;34m(self, env_creator, validate_env, policy_class, trainer_config, num_workers, local_worker, logdir, _setup)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39m# Create a number of @ray.remote workers.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_remote_workers \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 125\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_workers(\n\u001b[1;32m    126\u001b[0m     num_workers,\n\u001b[1;32m    127\u001b[0m     validate\u001b[39m=\u001b[39;49mtrainer_config\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mvalidate_workers_after_construction\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    128\u001b[0m )\n\u001b[1;32m    130\u001b[0m \u001b[39m# Create a local worker, if needed.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m# If num_workers > 0 and we don't have an env on the local worker,\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m# get the observation- and action spaces for each policy from\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39m# the first remote worker (which does have an env).\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    135\u001b[0m     local_worker\n\u001b[1;32m    136\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_remote_workers\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     )\n\u001b[1;32m    142\u001b[0m ):\n",
            "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py:269\u001b[0m, in \u001b[0;36mWorkerSet.add_workers\u001b[0;34m(self, num_workers, validate)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[39m# Validate here, whether all remote workers have been constructed properly\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m# and are \"up and running\". If not, the following will throw a RayError\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[39m# which needs to be handled by this WorkerSet's owner (usually\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[39m# a RLlib Algorithm instance).\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[39mif\u001b[39;00m validate:\n\u001b[0;32m--> 269\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforeach_worker(\u001b[39mlambda\u001b[39;49;00m w: w\u001b[39m.\u001b[39;49massert_healthy())\n",
            "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py:391\u001b[0m, in \u001b[0;36mWorkerSet.foreach_worker\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal_worker() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    390\u001b[0m     local_result \u001b[39m=\u001b[39m [func(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal_worker())]\n\u001b[0;32m--> 391\u001b[0m remote_results \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39;49mget([w\u001b[39m.\u001b[39;49mapply\u001b[39m.\u001b[39;49mremote(func) \u001b[39mfor\u001b[39;49;00m w \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mremote_workers()])\n\u001b[1;32m    392\u001b[0m \u001b[39mreturn\u001b[39;00m local_result \u001b[39m+\u001b[39m remote_results\n",
            "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[39mif\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    104\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(ray, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 105\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.10/site-packages/ray/_private/worker.py:2282\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2280\u001b[0m             \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mas_instanceof_cause()\n\u001b[1;32m   2281\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2282\u001b[0m             \u001b[39mraise\u001b[39;00m value\n\u001b[1;32m   2284\u001b[0m \u001b[39mif\u001b[39;00m is_individual_id:\n\u001b[1;32m   2285\u001b[0m     values \u001b[39m=\u001b[39m values[\u001b[39m0\u001b[39m]\n",
            "\u001b[0;31mRayActorError\u001b[0m: The actor died unexpectedly before finishing this task.\n\tclass_name: RolloutWorker\n\tactor_id: ec593e54d3a0444c06203f0d01000000\n\tpid: 3449\n\tnamespace: d04a69c9-10c1-43e4-9346-de76743a5ac2\n\tip: 172.21.194.143\nThe actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\nThe actor never ran - it was cancelled before it started running."
          ]
        }
      ],
      "source": [
        "# Create the PPO trainer.\n",
        "os.environ['RAY_DISABLE_MEMORY_MONITOR'] = '1'\n",
        "trainer = PPOTrainer(\n",
        "    env=Covid19RLlibEnvWrapper,\n",
        "    config=trainer_config,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvsQg49FKslR"
      },
      "source": [
        "## 3. Perform Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmCNTKcDKslR"
      },
      "source": [
        "And that's it! We are now ready to perform training by invoking `trainer.train()`; we call it for just a few number of iterations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rosuv0AtKslR",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "NUM_ITERS = 100\n",
        "for iteration in range(NUM_ITERS):\n",
        "    print(f'********** Iter : {iteration} **********')\n",
        "    result = trainer.train()\n",
        "    print(f'''episode_reward_mean: {result.get('episode_reward_mean')}''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HctwigPSKslR"
      },
      "source": [
        "By default, the results will be logged to a subdirectory of `~/ray_results`. This subdirectory will contain a file `params.json` which contains the hyperparameters, a file `result.json` which contains a training summary for each episode and a TensorBoard file that can be used to visualize training process with TensorBoard by running|\n",
        "```shell\n",
        "tensorboard --logdir ~/ray_results\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YInHZMtYKslS"
      },
      "source": [
        "## 4. Generate and Visualize the Environment's Dense Logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8hDNhyeKslS"
      },
      "source": [
        "At any point during training, we would also want to inspect the environment's dense logs in order to deep-dive into the training results. Introduced in our [basic tutorial](https://github.com/salesforce/ai-economist/blob/master/tutorials/economic_simulation_basic.ipynb#Visualize-using-dense-logging), dense logs are basically logs of each agent's states, actions and rewards at every point in time, along with a snapshot of the world state.\n",
        "\n",
        "There are two equivalent ways to fetch the environment's dense logs using the trainer object.\n",
        "\n",
        "a. Simply retrieve the dense log from the workers' environment objects\n",
        "\n",
        "b. Generate dense log(s) from the most recent trainer policy model weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7nf_Hy0KslS"
      },
      "source": [
        "### 4a. Simply retrieve the dense log from the workers' environment objects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbYDzVkvKslS"
      },
      "source": [
        "From each rollout worker, it's straightforward to retrieve the dense logs using some of the function attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOPkYoToKslS"
      },
      "outputs": [],
      "source": [
        "# Below, we fetch the dense logs for each rollout worker and environment within\n",
        "\n",
        "dense_logs = {}\n",
        "# Note: worker 0 is reserved for the trainer actor\n",
        "for worker in range((trainer_config[\"num_workers\"] > 0), trainer_config[\"num_workers\"] + 1):\n",
        "    for env_id in range(trainer_config[\"num_envs_per_worker\"]):\n",
        "        dense_logs[\"worker={};env_id={}\".format(worker, env_id)] = \\\n",
        "        trainer.workers.foreach_worker(lambda w: w.async_env)[worker].envs[env_id].env.previous_episode_dense_log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy5bGmvPKslS"
      },
      "outputs": [],
      "source": [
        "# We should have num_workers x num_envs_per_worker number of dense logs\n",
        "print(dense_logs.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm0S6QneKslS"
      },
      "source": [
        "### 4b. Generate a dense log from the most recent trainer policy model weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbILmlVrKslS"
      },
      "source": [
        "We may also use the trainer object directly to play out an episode. The advantage of this approach is that we can re-sample the policy model any number of times and generate several rollouts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2oIv-StKslS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "from utils import plotting  # plotting utilities for visualizing env. state\n",
        "\n",
        "def do_plot(env, ax, fig):\n",
        "    \"\"\"Plots world state during episode sampling.\"\"\"\n",
        "    maps = env.env.world.maps\n",
        "    locs = [agent.loc for agent in env.env.world.agents] \n",
        "\n",
        "    cmap_order = None\n",
        "    plotting.plot_map(maps, locs, ax, cmap_order)\n",
        "    ax.set_aspect('equal')\n",
        "    display.display(fig)\n",
        "    display.clear_output(wait=True)\n",
        "\n",
        "def generate_rollout_from_current_trainer_policy(\n",
        "    trainer, \n",
        "    env_obj,\n",
        "    num_dense_logs=1\n",
        "):\n",
        "    dense_logs = {}\n",
        "    for idx in range(num_dense_logs):\n",
        "        # Set initial states\n",
        "        agent_states = {}\n",
        "        for agent_idx in range(env_obj.env.n_agents):\n",
        "            agent_states[str(agent_idx)] = trainer.get_policy(\"a\").get_initial_state()\n",
        "        planner_states = trainer.get_policy(\"p\").get_initial_state()   \n",
        "\n",
        "        # Play out the episode\n",
        "        obs = env_obj.reset(force_dense_logging=True)\n",
        "        fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
        "        for t in range(env_obj.env.episode_length):\n",
        "            actions = {}\n",
        "            for agent_idx in range(env_obj.env.n_agents):\n",
        "                # Use the trainer object directly to sample actions for each agent\n",
        "                actions[str(agent_idx)] = trainer.compute_action(\n",
        "                    obs[str(agent_idx)], \n",
        "                    agent_states[str(agent_idx)], \n",
        "                    policy_id=\"a\",\n",
        "                    full_fetch=False\n",
        "                )\n",
        "\n",
        "            # Action sampling for the planner\n",
        "            actions[\"p\"] = trainer.compute_action(\n",
        "                obs['p'], \n",
        "                planner_states, \n",
        "                policy_id='p',\n",
        "                full_fetch=False\n",
        "            )\n",
        "\n",
        "            obs, rew, done, info = env_obj.step(actions)        \n",
        "            if ((t+1) % 100) == 0:\n",
        "                do_plot(env_obj, ax, fig)\n",
        "            if done['__all__']:\n",
        "                break\n",
        "        dense_logs[idx] = env_obj.env.dense_log\n",
        "    return dense_logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wj10lcDVKslT"
      },
      "outputs": [],
      "source": [
        "dense_logs = generate_rollout_from_current_trainer_policy(\n",
        "    trainer, \n",
        "    env_obj,\n",
        "    num_dense_logs=100\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRfC7ap8KslT"
      },
      "source": [
        "### Visualizing the episode dense logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJiAqD5NKslT"
      },
      "source": [
        "Once we obtain the dense logs, we can use the plotting utilities we have created to examine the episode dense logs and visualize the the world state, agent-wise quantities, movement, and trading events."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLbq2m3jKslT"
      },
      "outputs": [],
      "source": [
        "from utils import plotting  # plotting utilities for visualizing env. state\n",
        "\n",
        "dense_log_idx = 0\n",
        "for index, element in enumerate(dense_logs):\n",
        "  print('Plot ', index)\n",
        "  plotting.breakdown(dense_logs[index]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CgYa-IlKslT"
      },
      "outputs": [],
      "source": [
        "# Shutdown Ray after use\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzYAX5FYKslT"
      },
      "source": [
        "And that's it for now. See you in the [next](https://github.com/salesforce/ai-economist/blob/master/tutorials/two_level_curriculum_learning_with_rllib.md) tutorial :)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.10.4 ('ML': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "9dbfbadc71e42abc9cd558c210cdff0e47003e6a6f6a3b108a42ec1174a9608f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
